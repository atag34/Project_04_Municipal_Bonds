{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "import PyPDF2 \n",
    "import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumPages(self,password =''):\n",
    "    \"\"\"\n",
    "    Calculates the number of pages in this PDF file.\n",
    "\n",
    "    :return: number of pages\n",
    "    :rtype: int\n",
    "    :raises PdfReadError: if file is encrypted and restrictions prevent\n",
    "        this action.\n",
    "    \"\"\"\n",
    "\n",
    "    # Flattened pages will not work on an Encrypted PDF;\n",
    "    # the PDF file's page count is used in this case. Otherwise,\n",
    "    # the original method (flattened page count) is used.\n",
    "    if self.isEncrypted:\n",
    "        try:\n",
    "            self._override_encryption = True\n",
    "            self.decrypt(password)\n",
    "            return self.trailer[\"/Root\"][\"/Pages\"][\"/Count\"]\n",
    "        except:\n",
    "            raise utils.PdfReadError(\"File has not been decrypted\")\n",
    "        finally:\n",
    "            self._override_encryption = False\n",
    "    else:\n",
    "        if self.flattenedPages == None:\n",
    "            self._flatten()\n",
    "        return len(self.flattenedPages)\n",
    "\n",
    "numPages = property(lambda self: self.getNumPages(), None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping and pdf downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am specifically focusing on recent General Obligation Bonds which fall into the 'other' category on the [EMMA](https://emma.msrb.org/Search/Search.aspx) website. I ran this twice as there were too many issues to load onto the EMMA site in one iteration. Below the dates can be adjusted to replicated the dataset. I ended up getting documents for bonds between 06/01/2020 - 11/4/2020 for the final project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate where in my local machine the geckodriver is for using firefox.\n",
    "driver = webdriver.Firefox(executable_path=r'C:/Users/atag3/Desktop/NYC DSA Python EDA/Untitled Folder/geckodriver.exe')\n",
    "\n",
    "# we have to click through the first message accepting a disclaimer.\n",
    "driver.get('https://emma.msrb.org/Search/Search.aspx')\n",
    "butt = driver.find_elements_by_xpath('//*[@id=\"ctl00_mainContentArea_disclaimerContent_yesButton\"]')\n",
    "butt[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: Element <a id=\"issuesTab\"> could not be scrolled into view\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8b8724c78297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#change view to be by issuers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"issuesTab\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: Element <a id=\"issuesTab\"> could not be scrolled into view\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "select = Select(driver.find_element_by_id('purposeDropdownList'))\n",
    "\n",
    "# select purpose of muni bond as other\n",
    "select.select_by_visible_text('Other')\n",
    "\n",
    "select = Select(driver.find_element_by_id('securedByDropdownList'))\n",
    "\n",
    "# select repayment type as General Obligation Bond\n",
    "select.select_by_visible_text('General Obligation')\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"datedDateFrom\"]').send_keys('06/01/2020')\n",
    "driver.find_element_by_xpath('//*[@id=\"datedDateTo\"]').send_keys('08/30/2020')\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"runSearchButton\"]').click()\n",
    "time.sleep(4)\n",
    "\n",
    "#change view to be by issuers\n",
    "driver.find_element_by_xpath('//*[@id=\"issuesTab\"]').click()\n",
    "\n",
    "# \n",
    "select = Select(driver.find_element_by_name('lvIssues_length'))\n",
    "\n",
    "# select purpose of muni bond as other\n",
    "select.select_by_visible_text('100')\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/form/div[10]/div/div/div[2]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the page the way we want it to look, we can look through all the pages for bond names issuer names and links\n",
    "max_n = int(driver.find_element_by_id('lvIssues_info').text.split(' ')[5].replace(',',''))\n",
    "\n",
    "#Create an empty dataframe to save information to.\n",
    "doc_table = pd.DataFrame(columns=['Issuer Name', 'Description', 'State','Dated Date','link'])\n",
    "\n",
    "# num of pages to go through.\n",
    "its = int(np.ceil(max_n/100))\n",
    "\n",
    "for i in range(0,its):\n",
    "    html = driver.page_source\n",
    "    table = pd.read_html(html)[4]\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # look for the link to bond issue page.\n",
    "    table['link'] = [item.get('href') for item in soup.find_all(\"a\", href=re.compile(\"IssueView\"))]\n",
    "    \n",
    "    doc_table = doc_table.append(table,ignore_index=True)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #click to next page and run through the loop again.\n",
    "    driver.find_element_by_xpath('/html/body/form/div[9]/div[3]/div[2]/div[2]/div[6]/div[3]/div/div/div[5]/a[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crteate a bond id using the final section of the link. Note this is not a cusip.\n",
    "doc_table['ID']= [link.split('/')[-1] for link in doc_table['link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through our list of links and downlaod the pdfs.\n",
    "for i in range(6,len(doc_table)):\n",
    "    try:\n",
    "        link= doc_table['link'][i]\n",
    "        name= doc_table['ID'][i]\n",
    "        url = link.replace('..','https://emma.msrb.org')\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_xpath('//*[@id=\"ui-id-4\"]').click()\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # we are extracting the link to the official pdf from the page and downloading the file. In my case I am saving it to\n",
    "        # a specific folder I have created on a backup HDD drive since the pdf files can take up a lot of space.\n",
    "        \n",
    "        pdf_link = [item.get('href') for item in soup.find_all(\"a\", href=re.compile(\".pdf\"))][0]\n",
    "        urllib.request.urlretrieve('https://emma.msrb.org'+pdf_link, 'E:/Users/atag3/Documents/Project_Data/Pull2/'+name+'.pdf')\n",
    "        time.sleep(5)\n",
    "    except Exception:\n",
    "        #print name if error occurs.\n",
    "        print(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pikepdf import Pdf\n",
    "\n",
    "# get list of pdfs ion the previously used folder\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"E:/Users/atag3/Documents/Project_Data/Pull2/*.pdf\"):\n",
    "    txtfiles.append(file.replace('\\\\','/'))\n",
    "    \n",
    "#decrypt them and save them to a different folder using the same ID from the doc_table dataframe.\n",
    "for file in txtfiles:\n",
    "    try:\n",
    "        new_pdf = Pdf.new()\n",
    "        with Pdf.open(file) as pdf:\n",
    "            pdf.save('E:/Users/atag3/Documents/Project_Data/Pull2/decrypted/'+file.split('/')[-1])\n",
    "    except Exception:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list of the decrypted pdfs.\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"E:/Users/atag3/Documents/Project_Data/Pull2/decrypted/*.pdf\"):\n",
    "    txtfiles.append(file.replace('\\\\','/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and read in all of the pdfs we had downloaded.\n",
    "go_text = {}\n",
    "for file in txtfiles:\n",
    "    try:\n",
    "        #open allows you to read the file.\n",
    "        pdfFileObj = open(file,'rb')\n",
    "        #The pdfReader variable is a readable object that will be parsed.\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "        #Discerning the number of pages will allow us to parse through all the pages.\n",
    "        num_pages = pdfReader.numPages\n",
    "        count = 0\n",
    "        text = \"\"\n",
    "        #The while loop will read each page.\n",
    "        while count < num_pages:\n",
    "            pageObj = pdfReader.getPage(count)\n",
    "            count +=1\n",
    "            text += pageObj.extractText()\n",
    "        #This if statement exists to check if the above library returned words. It's done because PyPDF2 cannot read scanned files.\n",
    "        if text != \"\":\n",
    "            text = text\n",
    "        #If the above returns as False, we run the OCR library textract to #convert scanned/image based PDF files into text.\n",
    "        else:\n",
    "            #this might be able to help with document scans but I was running into issues and it only helped with a few documents.\n",
    "            #text = textract.process(fileurl, method='tesseract', language='eng')\n",
    "            continue\n",
    "        #Now we have a text variable that contains all the text derived from \n",
    "\n",
    "        go_text[file] = {'doc':text}\n",
    "    except Exception:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I pickled the two versions and recombined them after the fact. I also removed documents with a word count below 10,000 which seemed to be mostly amendment documents to the official issuing document or other reports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issuer Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>State</th>\n",
       "      <th>Dated Date</th>\n",
       "      <th>link</th>\n",
       "      <th>ID</th>\n",
       "      <th>doc</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADDISON PARK DISTRICT, DUPAGE COUNTY, ILLINOIS</td>\n",
       "      <td>GENERAL OBLIGATION LIMITED TAX PARK BONDS, SER...</td>\n",
       "      <td>IL</td>\n",
       "      <td>09/30/2020</td>\n",
       "      <td>../IssueView/Details/P1404329</td>\n",
       "      <td>P1404329</td>\n",
       "      <td>NEW ISSUES \\nS&amp;P Global Ratings:   \\nBOOK-EN...</td>\n",
       "      <td>300745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADDISON PARK DISTRICT, DUPAGE COUNTY, ILLINOIS</td>\n",
       "      <td>GENERAL OBLIGATION REFUNDING PARK BONDS (ALTER...</td>\n",
       "      <td>IL</td>\n",
       "      <td>09/30/2020</td>\n",
       "      <td>../IssueView/Details/P1404328</td>\n",
       "      <td>P1404328</td>\n",
       "      <td>NEW ISSUES \\nS&amp;P Global Ratings:   \\nBOOK-EN...</td>\n",
       "      <td>300745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIRONDACK CENTRAL SCHOOL DISTRICT, NEW YORK</td>\n",
       "      <td>GENERAL OBLIGATIONS BOND ANTICIPATION NOTES, 2020</td>\n",
       "      <td>NY</td>\n",
       "      <td>09/16/2020</td>\n",
       "      <td>../IssueView/Details/P2403616</td>\n",
       "      <td>P2403616</td>\n",
       "      <td>\\nOFFICIAL STATEMENT\\n \\nNEW ISSUE\\n \\nBOND A...</td>\n",
       "      <td>294184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALABAMA TOWN NEW YORK</td>\n",
       "      <td>BOND ANTICIPATION NOTES, 2020 SERIES A</td>\n",
       "      <td>NY</td>\n",
       "      <td>10/01/2020</td>\n",
       "      <td>../IssueView/Details/P1404548</td>\n",
       "      <td>P1404548</td>\n",
       "      <td>\\n \\nFINAL \\nOFFICIAL STATEMENT DATED \\nSEPTE...</td>\n",
       "      <td>150332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALFRED-ALMOND CENTRAL SCHOOL DISTRICT ALLEGANY...</td>\n",
       "      <td>BOND ANTICIPATION NOTES, 2020</td>\n",
       "      <td>NY</td>\n",
       "      <td>09/16/2020</td>\n",
       "      <td>../IssueView/Details/P1404126</td>\n",
       "      <td>P1404126</td>\n",
       "      <td>\\n \\nFINAL \\nOFFICIAL STATEMENT DATED\\n \\nSEP...</td>\n",
       "      <td>159201.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Issuer Name  \\\n",
       "2     ADDISON PARK DISTRICT, DUPAGE COUNTY, ILLINOIS   \n",
       "3     ADDISON PARK DISTRICT, DUPAGE COUNTY, ILLINOIS   \n",
       "4       ADIRONDACK CENTRAL SCHOOL DISTRICT, NEW YORK   \n",
       "5                              ALABAMA TOWN NEW YORK   \n",
       "7  ALFRED-ALMOND CENTRAL SCHOOL DISTRICT ALLEGANY...   \n",
       "\n",
       "                                         Description State  Dated Date  \\\n",
       "2  GENERAL OBLIGATION LIMITED TAX PARK BONDS, SER...    IL  09/30/2020   \n",
       "3  GENERAL OBLIGATION REFUNDING PARK BONDS (ALTER...    IL  09/30/2020   \n",
       "4  GENERAL OBLIGATIONS BOND ANTICIPATION NOTES, 2020    NY  09/16/2020   \n",
       "5             BOND ANTICIPATION NOTES, 2020 SERIES A    NY  10/01/2020   \n",
       "7                      BOND ANTICIPATION NOTES, 2020    NY  09/16/2020   \n",
       "\n",
       "                            link        ID  \\\n",
       "2  ../IssueView/Details/P1404329  P1404329   \n",
       "3  ../IssueView/Details/P1404328  P1404328   \n",
       "4  ../IssueView/Details/P2403616  P2403616   \n",
       "5  ../IssueView/Details/P1404548  P1404548   \n",
       "7  ../IssueView/Details/P1404126  P1404126   \n",
       "\n",
       "                                                 doc       len  \n",
       "2    NEW ISSUES \\nS&P Global Ratings:   \\nBOOK-EN...  300745.0  \n",
       "3    NEW ISSUES \\nS&P Global Ratings:   \\nBOOK-EN...  300745.0  \n",
       "4   \\nOFFICIAL STATEMENT\\n \\nNEW ISSUE\\n \\nBOND A...  294184.0  \n",
       "5   \\n \\nFINAL \\nOFFICIAL STATEMENT DATED \\nSEPTE...  150332.0  \n",
       "7   \\n \\nFINAL \\nOFFICIAL STATEMENT DATED\\n \\nSEP...  159201.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pickle\n",
    "#big_df2 = pd.DataFrame.from_dict(go_text, orient='index').dropna(how='all',axis=1)\n",
    "#big_df2.to_pickle(\"./doc_text_2.pkl\")\n",
    "muni_df = pd.read_pickle('muni_df.pkl')\n",
    "muni_df['len'] = muni_df['doc'].str.len()\n",
    "muni_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because of the length of some of the documents this can take over an hour or two to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a table of states and cities to try and use as stop words to remove geographic words from documents.\n",
    "cities = pd.read_csv('https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv', sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states= cities['State full'].unique().tolist()\n",
    "states = [x for x in states if pd.notnull(x)]\n",
    "states = [x.lower() for x in states]\n",
    "states= [words for segments in states for words in segments.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A bunch of specific stop words I added plus state names.\n",
    "specific_stops = ['texas',\n",
    "                 'city',\n",
    "                 'town',\n",
    "                 'county',\n",
    "                  'audit',\n",
    "                 'bidder',\n",
    "                 'township',\n",
    "                  'counties',\n",
    "                  'tax',\n",
    "                  'state',\n",
    "                  'bond',\n",
    "                  'bonds',\n",
    "                  'fort',\n",
    "                  'bend',\n",
    "                  'cities',\n",
    "                  'towns'\n",
    "                  'taxable',\n",
    "                  'disbursments',\n",
    "                  'bond',\n",
    "                 'billion', \n",
    "                  'stateTMs', \n",
    "                  'thousands',\n",
    "                  'proposition',\n",
    "                  'village',  \n",
    "                  'obetz', \n",
    "                  'villagetms',\n",
    "                  'cityTMs', \n",
    "                  'countyTMs', \n",
    "                  'commonwealth',\n",
    "                  'huntsville',\n",
    "                  'inflows', \n",
    "                  'basic', \n",
    "                  'outflows', \n",
    "                  'fiduciary', \n",
    "                  'wide', \n",
    "                  'actuarial',\n",
    "                  'return', \n",
    "                  'component',\n",
    "                  'depreciation',\n",
    "                  'oxford', \n",
    "                  'birmingham', \n",
    "                  'madison', \n",
    "                  'cityTMs',\n",
    "                  'districtTMs', \n",
    "                  'harris', \n",
    "                  'houston',\n",
    "                  'williamson', \n",
    "                  'rutherford',\n",
    "                  'municipalityTMs',\n",
    "                  'cont',\n",
    "                  'borough',\n",
    "                  'lexington', \n",
    "                  'fayette', \n",
    "                  'des', \n",
    "                  'san',\n",
    "                  'antonio',\n",
    "                  'francisco',\n",
    "                  'bay',\n",
    "                  'cpa',\n",
    "                  'travis',\n",
    "                  'austin'\n",
    "                  'miami',\n",
    "                  'opeb',\n",
    "                   'msrb',\n",
    "                  'quincy',\n",
    "                  'ehlers', \n",
    "                  'wrs', \n",
    "                  'brady',\n",
    "                  'quarles',\n",
    "                  'evers', \n",
    "                  'btsc', \n",
    "                  'subdivisionTMs', \n",
    "                  'underwriter',\n",
    "                  'registrar', \n",
    "                  'receipts', \n",
    "                  'dtcTMs', \n",
    "                  'cusip', \n",
    "                  'hereof',\n",
    "                  'jefferson',\n",
    "                  'townTMs',\n",
    "                  'bam', \n",
    "                  'ict', \n",
    "                  'rict',\n",
    "                  'trict',\n",
    "                  'distr',\n",
    "                  'distric', \n",
    "                  'istrict',\n",
    "                  'comptroller',\n",
    "                  'milwaukee',\n",
    "                  'illion'\n",
    "                  'chicago',\n",
    "                  'agm',\n",
    "                  'municipality',\n",
    "                  'municipalityTMs',\n",
    "                  'promissory',\n",
    "                  'left',\n",
    "                  'intentionally',\n",
    "                  'blank',\n",
    "                  'moines']+states "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "\n",
    "def preprocess(docs):\n",
    "    return_list = []\n",
    "    for content in docs:\n",
    "        content = content.lower()\n",
    "        content = content.replace('\\n','')\n",
    "\n",
    "        content = \"\".join([char for char in content if char not in string.punctuation])\n",
    "\n",
    "        words = word_tokenize(content)\n",
    "\n",
    "        stop_words = text.ENGLISH_STOP_WORDS.union(specific_stops)\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "\n",
    "        porter = PorterStemmer()\n",
    "        words= [porter.stem(word) for word in words]\n",
    "        return_list.append(words)\n",
    "    return return_list\n",
    "\n",
    "muni_df = muni_df.reset_index(drop=True)\n",
    "\n",
    "clean_text = preprocess(muni_df['doc'])\n",
    "\n",
    "\n",
    "\n",
    "#cat version for passing to vectorizer\n",
    "clean_text_cat = list(map(lambda x: ' '.join(x),clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_df['clean_text'] = clean_text_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_df.to_pickle(\"./muni_clean.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
